# ğŸ”Š Echo AI - Production RAG Chatbot

A production-ready RAG (Retrieval-Augmented Generation) chatbot with **persistent vector storage** using Pinecone.

## ğŸ’° Cost: $0/month

- **Frontend**: Streamlit
- **Vector DB**: **Pinecone** (persistent, cloud-native)
- **Embeddings**: HuggingFace (sentence-transformers)
- **LLM**: Groq API (free tier)
- **Hosting**: HuggingFace Spaces / Streamlit Cloud (free)

## âœ¨ Key Features

- ğŸ“„ **Multi-format ingestion**: Upload PDFs or scrape websites
- ğŸ’¬ **Conversational AI**: Context-aware responses with memory
- ğŸ“š **Source citations**: Shows which documents answers came from
- ğŸ¯ **Multi-client support**: Separate namespaces per client
- **ğŸ“Œ Persistent storage**: Data survives page refreshes (Pinecone)
- ğŸš€ **Production-ready**: No data loss, robust architecture

## ğŸ¯ Why Pinecone?

| Feature | ChromaDB (Old) | Pinecone (New) |
|---------|----------------|----------------|
| **Persistence** | âŒ Ephemeral on free hosting | âœ… Cloud-native, always persists |
| **Data Loss** | âŒ Resets on app restart | âœ… Never loses data |
| **Professional** | âš ï¸ Demo-quality | âœ… Production-grade |
| **Scalability** | âš ï¸ Local file-based | âœ… Serverless, auto-scales |
| **Free Tier** | âœ… Unlimited | âœ… 100K vectors, 1 index |

**Result**: Echo AI feels like a **real product**, not a fragile demo.

---

## ğŸš€ Quick Start (Local)

### 1. Clone & Setup

```bash
# Navigate to project
cd "e:\My Projects\AI Chatbot"

# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Get API Keys

#### Groq API (Required)
1. Visit: https://console.groq.com
2. Sign up (free)
3. Create API key
4. Copy key (starts with `gsk_...`)

**Free tier**: 30 req/min, 6K req/day

#### Pinecone API (Required)
1. Visit: https://www.pinecone.io
2. Sign up (free)
3. Create API key
4. Note your environment (e.g., `us-east-1`)

**Free tier**: 1 index, 100K vectors, unlimited queries

### 3. Configure Environment

```bash
# Copy example file
cp .env.example .env

# Edit .env and add your keys
GROQ_API_KEY=gsk_your_actual_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-east-1
```

### 4. Run Locally

```bash
streamlit run app.py
```

Opens at: http://localhost:8501

---

## ğŸ“¦ Deploy to HuggingFace Spaces (FREE)

### Option A: Web Interface

1. Go to: https://huggingface.co/spaces
2. Click "Create new Space"
3. Configure:
   - **Name**: `echo-ai`
   - **SDK**: Streamlit
   - **Hardware**: CPU basic (free)
4. Upload files:
   - `app.py`
   - `requirements.txt`
   - `packages.txt`
   - `README_SPACES.md` (rename to `README.md`)
5. Settings â†’ Repository secrets:
   - `GROQ_API_KEY`: Your Groq key
   - `PINECONE_API_KEY`: Your Pinecone key
   - `PINECONE_ENVIRONMENT`: `us-east-1`
6. Wait 5-10 minutes for build

### Option B: Git Push

```bash
# Clone your space
git clone https://huggingface.co/spaces/YOUR_USERNAME/echo-ai
cd echo-ai

# Copy files
cp "e:\My Projects\AI Chatbot\app.py" .
cp "e:\My Projects\AI Chatbot\requirements.txt" .
cp "e:\My Projects\AI Chatbot\packages.txt" .
cp "e:\My Projects\AI Chatbot\README_SPACES.md" README.md

# Commit and push
git add .
git commit -m "Deploy Echo AI"
git push
```

---

## ğŸ¯ Usage

### 1. Upload Documents
- Sidebar â†’ Upload PDF files
- OR enter website URLs (one per line)
- Click "ğŸš€ Process Documents"

### 2. Chat
- Type questions in chat input
- Echo AI answers using ONLY your documents
- Click "ğŸ“– Sources" to see references

### 3. Multi-Client Setup
- Change "Client/Company Name"
- Upload different documents
- Each client gets separate Pinecone namespace

**Data persists forever** - no need to re-upload!

---

## ğŸ”§ Customization

### Change LLM Model

```python
# In app.py, line ~185
llm = ChatGroq(
    model_name="llama-3.1-70b-versatile",  # Larger model
    # or "mixtral-8x7b-32768"  # Longer context
)
```

### Adjust Chunk Size

```python
# In app.py, line ~125
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1500,  # Increase for more context
    chunk_overlap=300,
)
```

### Modify Branding

```python
# In app.py, line ~191
prompt_template = f"""You are Echo AI, a helpful assistant for {client_name}."""
```

---

## ğŸŒ WordPress Integration

See `wordpress_integration.html` for:
- Full-page iframe embed
- Popup chat widget
- Inline section embed

Update `STREAMLIT_URL` to your deployed Echo AI URL.

---

## ğŸ“Š Free Tier Limits

### Groq API
- âœ… 30 requests/minute
- âœ… 6,000 requests/day
- âš ï¸ Rate limit errors if exceeded

### Pinecone
- âœ… 1 index (sufficient for all clients via namespaces)
- âœ… 100,000 vectors (~200 PDF pages)
- âœ… Unlimited queries
- âœ… **Persistent storage** (data never deleted)

### HuggingFace Spaces
- âœ… Unlimited usage
- âš ï¸ Sleeps after inactivity (~30s wake)
- âœ… **Works with Pinecone** (no local storage needed)

---

## ğŸ”’ Security

- âœ… API keys in secrets (not in code)
- âœ… `.env` excluded from git
- âœ… Pinecone data isolated by namespace
- âš ï¸ Free hosting = public apps
- ğŸ’¡ For sensitive data, use private Space ($9/mo)

---

## ğŸ› Troubleshooting

### "ModuleNotFoundError: pinecone"
```bash
pip install -r requirements.txt --upgrade
```

### "Pinecone initialization error"
- Check API key is correct
- Verify environment matches (e.g., `us-east-1`)
- Check Pinecone dashboard for index status

### "Index not found"
- App auto-creates index on first run
- Wait 30 seconds for index creation
- Refresh page

### Slow performance
- Free tier has cold starts (~30s)
- Pinecone queries are fast (<100ms)
- Upgrade hosting for instant wake

---

## ğŸ“ˆ Upgrade Path

### When to upgrade:

**Pinecone Paid ($70/month)**
- Need >100K vectors (>200 pages)
- Need multiple indexes
- Need dedicated resources

**Streamlit Cloud Pro ($20/month)**
- Need private apps
- Need custom domain
- Need instant wake (no cold starts)

**Groq Paid Tier**
- Need higher rate limits
- Need guaranteed uptime

---

## ğŸ’¡ Pinecone vs ChromaDB

| Scenario | ChromaDB | Pinecone |
|----------|----------|----------|
| **Local dev** | âœ… Great | âœ… Great |
| **Free cloud hosting** | âŒ Data resets | âœ… Persistent |
| **Client demos** | âŒ Breaks on refresh | âœ… Professional |
| **Production** | âš ï¸ Need paid hosting | âœ… Ready now |

**Verdict**: Pinecone makes Echo AI production-ready on free tier.

---

## ğŸ¤ Contributing

Contributions welcome!

---

## ğŸ“„ License

MIT License - free for commercial use

---

## ğŸ™ Credits

- **LangChain**: RAG framework
- **Streamlit**: UI framework
- **Groq**: Free LLM API
- **Pinecone**: Vector database
- **HuggingFace**: Embeddings & hosting

---

**Built with â¤ï¸ for production AI demos**

ğŸ”Š **Echo AI** - Your knowledge, amplified.
